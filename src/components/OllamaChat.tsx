import { useState, useEffect, useRef } from 'react'
import { motion, AnimatePresence } from 'framer-motion'
import { Send, Bot, User, Loader2, Zap, Code, FileText, Settings, Cpu, HardDrive } from 'lucide-react'

interface ChatMessage {
  id: string
  role: 'user' | 'assistant'
  content: string
  timestamp: string
  type?: 'text' | 'code' | 'file' | 'system'
}

interface OllamaChatProps {
  onLinOLSCommand?: (command: string) => void
  ecuFile?: File | null
}

export default function OllamaChat({ onLinOLSCommand, ecuFile }: OllamaChatProps) {
  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [input, setInput] = useState('')
  const [isLoading, setIsLoading] = useState(false)
  const [isConnected, setIsConnected] = useState(false)
  const [selectedModel, setSelectedModel] = useState('llama3.2')
  const [availableModels, setAvailableModels] = useState<string[]>([])
  const messagesEndRef = useRef<HTMLDivElement>(null)

  const ollamaModels = [
    { name: 'llama3.2', display: 'Llama 3.2 (Genel)', description: 'Genel amaÃ§lÄ± AI asistan' },
    { name: 'codellama', display: 'CodeLlama (Kod)', description: 'Kod yazma ve analiz' },
    { name: 'mistral', display: 'Mistral (HÄ±zlÄ±)', description: 'HÄ±zlÄ± yanÄ±tlar' },
    { name: 'neural-chat', display: 'Neural Chat (Teknik)', description: 'Teknik konular' }
  ]

  useEffect(() => {
    checkOllamaConnection()
    initializeChat()
  }, [])

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }

  const checkOllamaConnection = async () => {
    try {
      // Try direct connection first
      let response = await fetch('http://localhost:11434/api/tags')
      
      // If direct connection fails, try through nginx proxy
      if (!response.ok) {
        response = await fetch('/api/ollama/tags')
      }
      
      if (response.ok) {
        const data = await response.json()
        setAvailableModels(data.models?.map((m: any) => m.name) || [])
        setIsConnected(true)
        console.log('âœ… Ollama baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±:', data.models?.length || 0, 'model mevcut')
      }
    } catch (error) {
      console.log('âŒ Ollama baÄŸlantÄ±sÄ± kurulamadÄ±:', error)
      setIsConnected(false)
      
      // Show connection status in chat
      const errorMessage: ChatMessage = {
        id: Date.now().toString(),
        role: 'assistant',
        content: `ðŸ”Œ **Ollama BaÄŸlantÄ± Durumu**

âŒ Ollama servisine baÄŸlanÄ±lamadÄ±.

**Kontrol Edilecekler:**
â€¢ Docker container Ã§alÄ±ÅŸÄ±yor mu: \`docker ps | grep ollama\`
â€¢ Ollama servisi aktif mi: \`curl http://localhost:11434/api/tags\`
â€¢ Port 11434 aÃ§Ä±k mÄ±

**Manuel Test:**
\`docker exec -it nexaven-ollama ollama list\`

BaÄŸlantÄ± kurulana kadar LinOLS komutlarÄ± kullanÄ±labilir.`,
        timestamp: new Date().toISOString(),
        type: 'system'
      }
      
      setMessages(prev => [...prev, errorMessage])
    }
  }

  const initializeChat = () => {
    const welcomeMessage: ChatMessage = {
      id: Date.now().toString(),
      role: 'assistant',
      content: `ðŸ”§ **Zorlu ECU AI AsistanÄ±**

Merhaba! Ben ECU tuning konusunda size yardÄ±mcÄ± olacak AI asistanÄ±nÄ±zÄ±m.

**Yapabileceklerim:**
â€¢ ðŸš— ECU dosya analizi ve stage yazÄ±lÄ±m Ã¶nerileri
â€¢ ðŸ”§ LinOLS komutlarÄ± ve ayarlarÄ±
â€¢ ðŸ“Š Performance optimizasyonu tavsiyeleri
â€¢ ðŸ› ï¸ Tuning parametreleri hesaplama
â€¢ ðŸ“‹ Hata kodu analizi

**LinOLS KomutlarÄ±:**
\`/linols open\` - LinOLS arayÃ¼zÃ¼nÃ¼ aÃ§
\`/linols load [dosya]\` - ECU dosyasÄ±nÄ± yÃ¼kle
\`/linols stage1\` - Stage 1 ayarlarÄ± uygula
\`/linols stage2\` - Stage 2 ayarlarÄ± uygula
\`/linols export\` - DÃ¼zenlenmiÅŸ dosyayÄ± dÄ±ÅŸa aktar

Hangi konuda yardÄ±m istiyorsunuz?`,
      timestamp: new Date().toISOString(),
      type: 'system'
    }
    setMessages([welcomeMessage])
  }

  const sendMessage = async () => {
    if (!input.trim() || isLoading) return

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      role: 'user',
      content: input,
      timestamp: new Date().toISOString()
    }

    setMessages(prev => [...prev, userMessage])
    setInput('')
    setIsLoading(true)

    // Check for LinOLS commands
    if (input.startsWith('/linols')) {
      handleLinOLSCommand(input)
      setIsLoading(false)
      return
    }

    try {
      // Try direct connection first, then proxy
      let apiUrl = 'http://localhost:11434/api/generate'
      let response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: selectedModel,
          prompt: buildPrompt(input),
          stream: false,
          options: {
            temperature: 0.7,
            top_p: 0.9,
            max_tokens: 2000
          }
        }),
      })

      // If direct connection fails, try through nginx proxy
      if (!response.ok) {
        apiUrl = '/api/ollama/generate'
        response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: selectedModel,
            prompt: buildPrompt(input),
            stream: false,
            options: {
              temperature: 0.7,
              top_p: 0.9,
              max_tokens: 2000
            }
          }),
        })
      }

      if (response.ok) {
        const data = await response.json()
        const assistantMessage: ChatMessage = {
          id: (Date.now() + 1).toString(),
          role: 'assistant',
          content: data.response || 'YanÄ±t alÄ±namadÄ±.',
          timestamp: new Date().toISOString()
        }
        setMessages(prev => [...prev, assistantMessage])
      } else {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }
    } catch (error) {
      console.error('Ollama API HatasÄ±:', error)
      const errorMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: `âŒ **AI YanÄ±t HatasÄ±**

Ollama API'den yanÄ±t alÄ±namadÄ±: ${error}

**Ã‡Ã¶zÃ¼m Ã–nerileri:**
1. Model indirilmiÅŸ mi kontrol edin: \`docker exec nexaven-ollama ollama list\`
2. Model indirin: \`docker exec nexaven-ollama ollama pull ${selectedModel}\`
3. Ollama loglarÄ±nÄ± kontrol edin: \`docker logs nexaven-ollama\`

**Mevcut Modeller:**
${availableModels.length > 0 ? availableModels.map(m => `â€¢ ${m}`).join('\n') : 'HenÃ¼z model indirilmemiÅŸ'}

**LinOLS KomutlarÄ±** hala kullanÄ±labilir!`,
        timestamp: new Date().toISOString(),
        type: 'system'
      }
      setMessages(prev => [...prev, errorMessage])
    }

    setIsLoading(false)
  }

  const buildPrompt = (userInput: string) => {
    const context = `Sen bir ECU tuning uzmanÄ±sÄ±n. Zorlu ECU firmasÄ± iÃ§in Ã§alÄ±ÅŸÄ±yorsun ve mÃ¼ÅŸterilere ECU yazÄ±lÄ±m geliÅŸtirme konusunda yardÄ±m ediyorsun.

UzmanlÄ±k alanlarÄ±n:
- ECU dosya analizi ve modifikasyonu
- Stage 1, Stage 2, Stage 3 yazÄ±lÄ±m geliÅŸtirme
- LinOLS yazÄ±lÄ±mÄ± kullanÄ±mÄ±
- Performance optimizasyonu
- Turbo basÄ±nÃ§ ayarlarÄ±
- YakÄ±t haritasÄ± optimizasyonu
- DPF/EGR silme iÅŸlemleri
- Hata kodu analizi

${ecuFile ? `Åžu anda yÃ¼klÃ¼ ECU dosyasÄ±: ${ecuFile.name}` : 'HenÃ¼z ECU dosyasÄ± yÃ¼klenmemiÅŸ.'}

KullanÄ±cÄ± sorusu: ${userInput}

LÃ¼tfen profesyonel, teknik ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±tla. Gerekirse LinOLS komutlarÄ± Ã¶ner.`

    return context
  }

  const handleLinOLSCommand = (command: string) => {
    const cmd = command.toLowerCase().trim()
    
    let responseMessage = ''
    
    if (cmd === '/linols open') {
      responseMessage = 'ðŸ”§ **LinOLS ArayÃ¼zÃ¼ AÃ§Ä±lÄ±yor...**\n\nLinOLS web arayÃ¼zÃ¼ne yÃ¶nlendiriliyorsunuz.'
      onLinOLSCommand?.('open')
    } else if (cmd.startsWith('/linols load')) {
      responseMessage = 'ðŸ“ **ECU DosyasÄ± YÃ¼kleniyor...**\n\nDosya yÃ¼kleme iÅŸlemi baÅŸlatÄ±lÄ±yor.'
      onLinOLSCommand?.('load')
    } else if (cmd === '/linols stage1') {
      responseMessage = 'âš¡ **Stage 1 AyarlarÄ± UygulanÄ±yor...**\n\nâ€¢ Turbo basÄ±ncÄ±: +0.2 bar\nâ€¢ YakÄ±t haritasÄ±: %15 artÄ±ÅŸ\nâ€¢ AteÅŸleme avansÄ±: +2Â°\nâ€¢ HÄ±z limiti: KaldÄ±rÄ±ldÄ±'
      onLinOLSCommand?.('stage1')
    } else if (cmd === '/linols stage2') {
      responseMessage = 'ðŸš€ **Stage 2 AyarlarÄ± UygulanÄ±yor...**\n\nâ€¢ Turbo basÄ±ncÄ±: +0.4 bar\nâ€¢ YakÄ±t haritasÄ±: %25 artÄ±ÅŸ\nâ€¢ AteÅŸleme avansÄ±: +4Â°\nâ€¢ Intercooler optimizasyonu\nâ€¢ Egzoz backpressure dÃ¼ÅŸÃ¼rme'
      onLinOLSCommand?.('stage2')
    } else if (cmd === '/linols export') {
      responseMessage = 'ðŸ’¾ **Dosya DÄ±ÅŸa AktarÄ±lÄ±yor...**\n\nDÃ¼zenlenmiÅŸ ECU dosyasÄ± hazÄ±rlanÄ±yor.'
      onLinOLSCommand?.('export')
    } else {
      responseMessage = `âŒ **Bilinmeyen Komut**\n\nGeÃ§erli LinOLS komutlarÄ±:\nâ€¢ \`/linols open\` - ArayÃ¼zÃ¼ aÃ§\nâ€¢ \`/linols load\` - Dosya yÃ¼kle\nâ€¢ \`/linols stage1\` - Stage 1 uygula\nâ€¢ \`/linols stage2\` - Stage 2 uygula\nâ€¢ \`/linols export\` - Dosya dÄ±ÅŸa aktar`
    }

    const systemMessage: ChatMessage = {
      id: (Date.now() + 1).toString(),
      role: 'assistant',
      content: responseMessage,
      timestamp: new Date().toISOString(),
      type: 'system'
    }

    setMessages(prev => [...prev, systemMessage])
  }

  const getMessageIcon = (message: ChatMessage) => {
    if (message.role === 'user') return <User className="w-5 h-5" />
    if (message.type === 'system') return <Settings className="w-5 h-5" />
    return <Bot className="w-5 h-5" />
  }

  const getMessageStyle = (message: ChatMessage) => {
    if (message.role === 'user') {
      return 'bg-blue-500/20 border-blue-500/50 text-blue-100 ml-12'
    }
    if (message.type === 'system') {
      return 'bg-orange-500/20 border-orange-500/50 text-orange-100 mr-12'
    }
    return 'bg-green-500/20 border-green-500/50 text-green-100 mr-12'
  }

  return (
    <div className="flex flex-col h-full bg-black/40 border border-white/10 rounded-2xl overflow-hidden">
      {/* Header */}
      <div className="p-4 border-b border-white/10 bg-white/5">
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-3">
            <div className="p-2 bg-gradient-to-r from-red-500 to-orange-500 rounded-lg">
              <Bot className="w-6 h-6 text-white" />
            </div>
            <div>
              <h3 className="text-white font-bold">ECU AI AsistanÄ±</h3>
              <div className="flex items-center gap-2">
                <div className={`w-2 h-2 rounded-full ${isConnected ? 'bg-green-400' : 'bg-red-400'}`} />
                <span className="text-white/60 text-sm">
                  {isConnected ? 'Ollama BaÄŸlÄ±' : 'Ollama BaÄŸlantÄ±sÄ±z'}
                </span>
              </div>
            </div>
          </div>

          {/* Model Selector */}
          <select
            value={selectedModel}
            onChange={(e) => setSelectedModel(e.target.value)}
            className="px-3 py-1 bg-white/10 border border-white/20 rounded-lg text-white text-sm focus:outline-none focus:border-red-500"
          >
            {ollamaModels.map(model => (
              <option key={model.name} value={model.name} className="bg-gray-800">
                {model.display}
              </option>
            ))}
          </select>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        <AnimatePresence>
          {messages.map((message) => (
            <motion.div
              key={message.id}
              initial={{ opacity: 0, y: 20 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0, y: -20 }}
              className={`p-4 rounded-xl border ${getMessageStyle(message)}`}
            >
              <div className="flex items-start gap-3">
                <div className="p-2 bg-white/10 rounded-lg">
                  {getMessageIcon(message)}
                </div>
                <div className="flex-1">
                  <div className="flex items-center gap-2 mb-2">
                    <span className="font-semibold">
                      {message.role === 'user' ? 'Siz' : message.type === 'system' ? 'Sistem' : 'AI Asistan'}
                    </span>
                    <span className="text-xs opacity-60">
                      {new Date(message.timestamp).toLocaleTimeString('tr-TR')}
                    </span>
                  </div>
                  <div className="prose prose-invert max-w-none">
                    {message.content.split('\n').map((line, idx) => (
                      <p key={idx} className="mb-2 last:mb-0">
                        {line.startsWith('`') && line.endsWith('`') ? (
                          <code className="px-2 py-1 bg-black/30 rounded text-sm font-mono">
                            {line.slice(1, -1)}
                          </code>
                        ) : line.startsWith('â€¢') ? (
                          <span className="flex items-start gap-2">
                            <span className="text-red-400 mt-1">â€¢</span>
                            <span>{line.slice(1).trim()}</span>
                          </span>
                        ) : (
                          line
                        )}
                      </p>
                    ))}
                  </div>
                </div>
              </div>
            </motion.div>
          ))}
        </AnimatePresence>

        {isLoading && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            className="flex items-center gap-3 p-4 bg-white/5 rounded-xl border border-white/10"
          >
            <Loader2 className="w-5 h-5 animate-spin text-red-400" />
            <span className="text-white/60">AI dÃ¼ÅŸÃ¼nÃ¼yor...</span>
          </motion.div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* Input */}
      <div className="p-4 border-t border-white/10 bg-white/5">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
            placeholder="ECU tuning hakkÄ±nda soru sorun veya /linols komutlarÄ± kullanÄ±n..."
            className="flex-1 px-4 py-3 bg-white/10 border border-white/20 rounded-xl text-white placeholder:text-white/40 focus:outline-none focus:border-red-500"
            disabled={isLoading}
          />
          <button
            onClick={sendMessage}
            disabled={isLoading || !input.trim()}
            className="px-6 py-3 bg-gradient-to-r from-red-500 to-orange-500 rounded-xl text-white font-semibold hover:shadow-lg hover:shadow-red-500/25 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <Send className="w-5 h-5" />
          </button>
        </div>

        {/* Quick Commands */}
        <div className="flex flex-wrap gap-2 mt-3">
          {[
            { cmd: '/linols open', label: 'ðŸ”§ LinOLS AÃ§' },
            { cmd: '/linols stage1', label: 'âš¡ Stage 1' },
            { cmd: '/linols stage2', label: 'ðŸš€ Stage 2' },
            { cmd: 'ECU dosya analizi yap', label: 'ðŸ“Š Analiz' }
          ].map((quick) => (
            <button
              key={quick.cmd}
              onClick={() => setInput(quick.cmd)}
              className="px-3 py-1 bg-white/10 hover:bg-white/20 border border-white/20 rounded-lg text-white/70 text-sm transition-all"
            >
              {quick.label}
            </button>
          ))}
        </div>
      </div>
    </div>
  )
}